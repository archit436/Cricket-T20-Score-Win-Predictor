{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5019213",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "The purpose of the code in this notebook is to take the data stored in yaml files from our Kaggle Dataset, and convert it to a format appropriate for our model developement. We will process and store data for 1st and 2nd innings seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55eb6b",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a661d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing the necessary libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yaml import safe_load\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# safe_load will allow us to parse a YAML string and convert it into a python object.\n",
    "# YAML is a data serialization standard used generally in an exchange b/w diff languages.\n",
    "# tqdm is used to create progress bars for loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c390e1a",
   "metadata": {},
   "source": [
    "## 1. Data Import\n",
    "\n",
    "We will be using data from the following Kaggle dataset: https://www.kaggle.com/datasets/veeralakrishna/cricsheet-a-retrosheet-for-cricket. In this dataset, we will look at the data of T20 matches, which has data for 1,433 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94f038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the path of all the YAML files in the data. \n",
    "# There are 1433 YAML files with each file corresponding to a T20 match.\n",
    "filenames = []\n",
    "for file in os.listdir('data'):\n",
    "    filenames.append(os.path.join('data', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7a01a2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████▉| 1432/1433 [04:29<00:00,  5.32it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(filenames):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# For each file, we open it, load the contents and normalize into a DF\u001b[39;00m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Then, we add a column with our generated match id and append to the main DataFrame.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m         main_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([main_df, df])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlGeneral_env\\Lib\\site-packages\\pandas\\io\\json\\_normalize.py:445\u001b[0m, in \u001b[0;36mjson_normalize\u001b[1;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[0;32m    443\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# check to see if a simple recursive function is possible to\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# improve performance (see #15621) but only for cases such\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# as pd.Dataframe(data) or pd.Dataframe(data, sep)\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    451\u001b[0m     record_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m max_level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    456\u001b[0m ):\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Transfer the contents from each YAML file to a pandas DataFrame.\n",
    "main_df = pd.DataFrame()\n",
    "# Iterate over all the files.\n",
    "for file in tqdm(filenames):\n",
    "    with open(file, 'r') as f:\n",
    "        # For each file, we open it, load the contents and normalize into a DF\n",
    "        # Then, we add a column with our generated match id and append to the main DataFrame.\n",
    "        df = pd.json_normalize(safe_load(f))\n",
    "        main_df = pd.concat([main_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f26ac6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a copy of the dataframe for use for the second innings.\n",
    "main_second_df = main_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293ede1",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning for 1st Innings\n",
    "\n",
    "Next, we drop the unrequired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ed47300",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Discard the data features that are not required for our model developement.\n",
    "main_df.drop(columns = [\n",
    "    'meta.data_version',\n",
    "    'meta.created',\n",
    "    'meta.revision',\n",
    "    'info.outcome.bowl_out',\n",
    "    'info.bowl_out',\n",
    "    'info.supersubs.South Africa',\n",
    "    'info.supersubs.New Zealand',\n",
    "    'info.outcome.eliminator',\n",
    "    'info.outcome.result',\n",
    "    'info.outcome.method',\n",
    "    'info.neutral_venue',\n",
    "    'info.match_type_number',\n",
    "    'info.outcome.by.runs',\n",
    "    'info.outcome.by.wickets',\n",
    "], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb893f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1432, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddeebf9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "info.gender\n",
       "male      966\n",
       "female    466\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['info.gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5c1857",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(966, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter and segregate the data pertaining to men's T20 cricket matches.\n",
    "main_df = main_df.loc[main_df['info.gender'] == 'male']\n",
    "# Remove gender column from data, since it is the same value for all entries.\n",
    "main_df.drop(columns = ['info.gender'], inplace = True)\n",
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f498808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "info.match_type\n",
       "T20    966\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure all the data entries pertain to T20 matches.\n",
    "main_df['info.match_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1665695e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "info.overs\n",
       "20    963\n",
       "50      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure all the data entries pertain to 20 over matches.\n",
    "main_df['info.overs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f3cac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data to only include data from 20 over matches.\n",
    "main_df = main_df.loc[main_df['info.overs'] == 20]\n",
    "# Also, remove the columns of overs and match type since the value is the same for all entries.\n",
    "main_df.drop(columns = ['info.overs','info.match_type'], inplace = True)\n",
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ec7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and save the dataFrame in a file using pickle.\n",
    "# This enables us to not have to revisit the YAML files and load the data faster.\n",
    "import pickle\n",
    "pickle.dump(main_df, open('dataset_level1_first_innings.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50445360",
   "metadata": {},
   "source": [
    "## 3. Data Processing for 1st Innings\n",
    "\n",
    "The main goal is to take the current data from a match-by-match format to a delivery-by-delivery format. This data will be more valuable given that we want to train our model to make predictions from different points within a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967bdf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: {'batsman': 'AJ Finch',\n",
       "  'bowler': 'SL Malinga',\n",
       "  'non_striker': 'M Klinger',\n",
       "  'runs': {'batsman': 0, 'extras': 0, 'total': 0}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the file into a DataFrame called matches for use moving forward.\n",
    "import pickle\n",
    "matches_df = pickle.load(open('dataset_level1_first_innings.pkl', 'rb'))\n",
    "\n",
    "# Trial Data Access\n",
    "# We access the first delivery of the first innings of the first match in our data.\n",
    "# The deliveries are in the form of a list of single-element dictionaries for each delivery.\n",
    "# Each dictionary has dictionaries within to capture details for that delivery.\n",
    "matches_df.iloc[0]['innings'][0]['1st innings']['deliveries'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd347d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a delivery-by-delivery setup for all the matches.\n",
    "# Declare a variable to assign a unique match id to every match.\n",
    "matchIdx = 1\n",
    "# Declare a list, where each element will be a dictionary corresponding to a single delivery.\n",
    "# We want to populate this list, and then construct a DataFrame using it.\n",
    "# This is more efficient than creating a DataFrame and appending to it.\n",
    "delivery_data = []\n",
    "# Iterate through every line item (match) in the matches DataFrame.\n",
    "for index, row in matches_df.iterrows():\n",
    "    # Skip some matches with faulty data.\n",
    "    if matchIdx in [75,108,150,180,268,360,443,458,584,748,982,1052,1111,1226,1345]:\n",
    "        matchIdx += 1\n",
    "        continue\n",
    "    # Iterate through every dictionary in the list of deliveries, where each dictionary is a single element\n",
    "    # struct with details for that delivery.\n",
    "    for ball in row['innings'][0]['1st innings']['deliveries']:\n",
    "        for key in ball.keys():\n",
    "            # Create a dictionary to extract and store details for each delivery.\n",
    "            delivery_info = {\n",
    "                'match_id': matchIdx,\n",
    "                'teams': row['info.teams'],\n",
    "                'batting_team': row['innings'][0]['1st innings']['team'],\n",
    "                'ball': key,\n",
    "                'batsman': ball[key]['batsman'],\n",
    "                'bowler': ball[key]['bowler'],\n",
    "                'runs': ball[key]['runs']['total'],\n",
    "                'city': row['info.city'],\n",
    "                'venue': row['info.venue'],\n",
    "                'player_dismissed': ball[key].get('wicket', {}).get('player_out', '0')\n",
    "            }\n",
    "            # Append the dictionary to the list of dictionaries for each delivery.\n",
    "            delivery_data.append(delivery_info)\n",
    "    # Increment the match id.\n",
    "    matchIdx += 1\n",
    "\n",
    "# Create a data frame to capture delivery-by-delivery data.\n",
    "delivery_df = pd.DataFrame(delivery_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1b02e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>teams</th>\n",
       "      <th>batting_team</th>\n",
       "      <th>ball</th>\n",
       "      <th>batsman</th>\n",
       "      <th>bowler</th>\n",
       "      <th>runs</th>\n",
       "      <th>city</th>\n",
       "      <th>venue</th>\n",
       "      <th>player_dismissed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Australia, Sri Lanka]</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AJ Finch</td>\n",
       "      <td>SL Malinga</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Melbourne Cricket Ground</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Australia, Sri Lanka]</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.2</td>\n",
       "      <td>AJ Finch</td>\n",
       "      <td>SL Malinga</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Melbourne Cricket Ground</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[Australia, Sri Lanka]</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.3</td>\n",
       "      <td>AJ Finch</td>\n",
       "      <td>SL Malinga</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Melbourne Cricket Ground</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[Australia, Sri Lanka]</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.4</td>\n",
       "      <td>M Klinger</td>\n",
       "      <td>SL Malinga</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Melbourne Cricket Ground</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[Australia, Sri Lanka]</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0.5</td>\n",
       "      <td>M Klinger</td>\n",
       "      <td>SL Malinga</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Melbourne Cricket Ground</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115320</th>\n",
       "      <td>963</td>\n",
       "      <td>[Sri Lanka, Australia]</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>19.3</td>\n",
       "      <td>SMSM Senanayake</td>\n",
       "      <td>MA Starc</td>\n",
       "      <td>1</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>R Premadasa Stadium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115321</th>\n",
       "      <td>963</td>\n",
       "      <td>[Sri Lanka, Australia]</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>19.4</td>\n",
       "      <td>DM de Silva</td>\n",
       "      <td>MA Starc</td>\n",
       "      <td>0</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>R Premadasa Stadium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115322</th>\n",
       "      <td>963</td>\n",
       "      <td>[Sri Lanka, Australia]</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>19.5</td>\n",
       "      <td>DM de Silva</td>\n",
       "      <td>MA Starc</td>\n",
       "      <td>0</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>R Premadasa Stadium</td>\n",
       "      <td>DM de Silva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115323</th>\n",
       "      <td>963</td>\n",
       "      <td>[Sri Lanka, Australia]</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>19.6</td>\n",
       "      <td>SMSM Senanayake</td>\n",
       "      <td>MA Starc</td>\n",
       "      <td>2</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>R Premadasa Stadium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115324</th>\n",
       "      <td>963</td>\n",
       "      <td>[Sri Lanka, Australia]</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>19.7</td>\n",
       "      <td>SMSM Senanayake</td>\n",
       "      <td>MA Starc</td>\n",
       "      <td>1</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>R Premadasa Stadium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115325 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        match_id                   teams batting_team  ball          batsman  \\\n",
       "0              1  [Australia, Sri Lanka]    Australia   0.1         AJ Finch   \n",
       "1              1  [Australia, Sri Lanka]    Australia   0.2         AJ Finch   \n",
       "2              1  [Australia, Sri Lanka]    Australia   0.3         AJ Finch   \n",
       "3              1  [Australia, Sri Lanka]    Australia   0.4        M Klinger   \n",
       "4              1  [Australia, Sri Lanka]    Australia   0.5        M Klinger   \n",
       "...          ...                     ...          ...   ...              ...   \n",
       "115320       963  [Sri Lanka, Australia]    Sri Lanka  19.3  SMSM Senanayake   \n",
       "115321       963  [Sri Lanka, Australia]    Sri Lanka  19.4      DM de Silva   \n",
       "115322       963  [Sri Lanka, Australia]    Sri Lanka  19.5      DM de Silva   \n",
       "115323       963  [Sri Lanka, Australia]    Sri Lanka  19.6  SMSM Senanayake   \n",
       "115324       963  [Sri Lanka, Australia]    Sri Lanka  19.7  SMSM Senanayake   \n",
       "\n",
       "            bowler  runs     city                     venue player_dismissed  \n",
       "0       SL Malinga     0      NaN  Melbourne Cricket Ground                0  \n",
       "1       SL Malinga     0      NaN  Melbourne Cricket Ground                0  \n",
       "2       SL Malinga     1      NaN  Melbourne Cricket Ground                0  \n",
       "3       SL Malinga     2      NaN  Melbourne Cricket Ground                0  \n",
       "4       SL Malinga     0      NaN  Melbourne Cricket Ground                0  \n",
       "...            ...   ...      ...                       ...              ...  \n",
       "115320    MA Starc     1  Colombo       R Premadasa Stadium                0  \n",
       "115321    MA Starc     0  Colombo       R Premadasa Stadium                0  \n",
       "115322    MA Starc     0  Colombo       R Premadasa Stadium      DM de Silva  \n",
       "115323    MA Starc     2  Colombo       R Premadasa Stadium                0  \n",
       "115324    MA Starc     1  Colombo       R Premadasa Stadium                0  \n",
       "\n",
       "[115325 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delivery_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf62cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We design a function to extract the name of the bowling team.\n",
    "def bowlingTeam(row):\n",
    "    # For a given delivery, look at the team names in the teams column\n",
    "    for team in row['teams']:\n",
    "        # Find the bowling team.\n",
    "        if team != row['batting_team']:\n",
    "            return team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df48c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a bowling team column to the delivery dataFrame and remove the teams column.\n",
    "delivery_df['bowling_team'] = delivery_df.apply(bowlingTeam, 1)\n",
    "delivery_df.drop(columns = ['teams'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62d78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data available for each team\n",
    "teams_frequency = delivery_df['batting_team'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd54a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will filter the data for only the top 10 teams, to optimize the model's performance.\n",
    "top_10_teams = teams_frequency.head(10).index\n",
    "delivery_df = delivery_df[delivery_df['batting_team'].isin(top_10_teams)]\n",
    "delivery_df = delivery_df[delivery_df['bowling_team'].isin(top_10_teams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09783098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a backup of the delivery DataFrame and create a pickle dump.\n",
    "final_df = delivery_df[['match_id', 'batting_team', 'bowling_team', 'ball', 'runs', 'player_dismissed', 'city', 'venue']]\n",
    "pickle.dump(final_df, open('dataset_level2_first_innings.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b8cda",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning for 2nd Innings\n",
    "\n",
    "We repeat the same steps "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
